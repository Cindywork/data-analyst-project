{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "\n",
    "Our product does not cover routine, wellness or preventive care.  We believe that costs that pet owners can expect periodically and budget for should be separate from an insurance policy meant to cover accidents and illnesses.\n",
    "\n",
    "Use the data contained in p2_data.csv to build a binary classifier to predict the “PreventiveFlag” label using the text features provided.  This model can be used to automate the detection of ineligible line items.  The expected output are prediction probabilities for rows 10001 through 11000, where the labels are currently null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Data\n",
    "\n",
    "To get an idea what data is being dealt with, loading the data and use data visualization tools to draw some insights from it. Below is the Power BI visualization of the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/PetPic01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "1. There're total of <font color='red'>10,000</font> records\n",
    "2. Only <font color='red'>6.78%</font> of the records are categorized as \"Preventive\"\n",
    "3. From the left-bottom word cloud we could see the most frequent diagnosis\n",
    "4. It seems ItemDescription has the format <font color='red'>'Name: Description'</font>\n",
    "5. Diagnosis doesn't say much about the category.\n",
    "\n",
    "#### Comments:\n",
    "* It would be really interesting to see what are the most common words in Diagnosis/ItemDescription for preventive diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count word frequencies for [PreventiveFlag = 1] records\n",
    "\n",
    "Now load the original data into pandas dataframe, and filter by PreventiveFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ItemDescription</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>PreventiveFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Shayna:  Leptospirosis Vaccine</td>\n",
       "      <td>Transitional Cell Carcinoma Work up for transi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>RAPHAEL:  Canine Rabies Booster 3 year</td>\n",
       "      <td>Lyme Postive test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>Reese:  Bordetella Oral - Annual</td>\n",
       "      <td>Exam &amp; Anal Sac Expression</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938</th>\n",
       "      <td>9939</td>\n",
       "      <td>Tiya:  Bordetella, Booster (Injectable)</td>\n",
       "      <td>Deciduous Teeth Retained, Pre-Ops for Extraction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9939</th>\n",
       "      <td>9940</td>\n",
       "      <td>Tiya:  PREPAID Fecal via Centrifugation</td>\n",
       "      <td>Deciduous Teeth Retained, Pre-Ops for Extraction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9941</th>\n",
       "      <td>9942</td>\n",
       "      <td>Tiya:  Parvovirus VACCINE Level (DA2PPV)</td>\n",
       "      <td>Deciduous Teeth Retained, Pre-Ops for Extraction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           ItemDescription  \\\n",
       "13      14            Shayna:  Leptospirosis Vaccine   \n",
       "47      48    RAPHAEL:  Canine Rabies Booster 3 year   \n",
       "52      53          Reese:  Bordetella Oral - Annual   \n",
       "...    ...                                       ...   \n",
       "9938  9939   Tiya:  Bordetella, Booster (Injectable)   \n",
       "9939  9940   Tiya:  PREPAID Fecal via Centrifugation   \n",
       "9941  9942  Tiya:  Parvovirus VACCINE Level (DA2PPV)   \n",
       "\n",
       "                                              Diagnosis  PreventiveFlag  \n",
       "13    Transitional Cell Carcinoma Work up for transi...               1  \n",
       "47                                   Lyme Postive test                1  \n",
       "52                          Exam & Anal Sac Expression                1  \n",
       "...                                                 ...             ...  \n",
       "9938  Deciduous Teeth Retained, Pre-Ops for Extraction                1  \n",
       "9939  Deciduous Teeth Retained, Pre-Ops for Extraction                1  \n",
       "9941  Deciduous Teeth Retained, Pre-Ops for Extraction                1  \n",
       "\n",
       "[678 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ntest = 10000\n",
    "df_p2 = pd.read_csv('./Data/p2_data.csv', encoding='latin1', nrows=ntest)\n",
    "df_p2_pflag = df_p2.loc[df_p2['PreventiveFlag'] == 1]\n",
    "\n",
    "pd.set_option('display.max_rows', 7)\n",
    "df_p2_pflag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ItemDescription</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>PreventiveFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Six:  Urgent Care Exam - Daytime (8am-6pm)</td>\n",
       "      <td>colitis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jafar:  Office Visit/Physical Exam</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jafar:  Fecal Smears</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>Stella:  Doxycycline 100mg/ml</td>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>MILLIE:  Adequan Injection per cc</td>\n",
       "      <td>Complications of TPLO (Millie only)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>MILLIE:  Biohazard Waste Disposal Fee</td>\n",
       "      <td>Complications of TPLO (Millie only)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9322 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                             ItemDescription  \\\n",
       "0         1  Six:  Urgent Care Exam - Daytime (8am-6pm)   \n",
       "1         2          Jafar:  Office Visit/Physical Exam   \n",
       "2         3                       Jafar:  Fecal Smears    \n",
       "...     ...                                         ...   \n",
       "9997   9998               Stella:  Doxycycline 100mg/ml   \n",
       "9998   9999           MILLIE:  Adequan Injection per cc   \n",
       "9999  10000       MILLIE:  Biohazard Waste Disposal Fee   \n",
       "\n",
       "                                 Diagnosis  PreventiveFlag  \n",
       "0                                 colitis                0  \n",
       "1                          Stomach Issues                0  \n",
       "2                          Stomach Issues                0  \n",
       "...                                    ...             ...  \n",
       "9997                        Heart Disease                0  \n",
       "9998  Complications of TPLO (Millie only)                0  \n",
       "9999  Complications of TPLO (Millie only)                0  \n",
       "\n",
       "[9322 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2_npflag = df_p2.loc[df_p2['PreventiveFlag'] == 0]\n",
    "df_p2_npflag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count word frequencies for column ItemDescription, we analyse this column because the other column, 'Diagnosis', doesn't seem to have high relation to the category, but we'll see in later sections when we train our classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "def GetItemDescW2Freq(df):\n",
    "    dict_w2c = defaultdict(lambda:0)\n",
    "    ct = 0\n",
    "    for index, row in df['ItemDescription'].iteritems():\n",
    "        words = []\n",
    "        try:\n",
    "            index_desc = row.index(':') + 1\n",
    "            words = [word.strip(string.punctuation) for word in row[index_desc:].split()]\n",
    "        except:\n",
    "            words = [word.strip(string.punctuation) for word in row.split()]\n",
    "        \n",
    "        for word in words:\n",
    "            dict_w2c[word] += 1.0\n",
    "            ct += 1\n",
    "    for word in dict_w2c:\n",
    "        dict_w2c[word] *= 100\n",
    "        dict_w2c[word] /= ct\n",
    "    sf = pd.Series(dict_w2c)\n",
    "    dict_w2c = pd.DataFrame({'word':sf.index, 'count':sf.values})\n",
    "    return dict_w2c\n",
    "\n",
    "# Get word -> count dict from [PreventiveFlag == 1] records\n",
    "df_w2c_id_p = GetItemDescW2Freq(df_p2_pflag)\n",
    "df_w2c_id_p['is_preventive'] = True\n",
    "\n",
    "# Get word -> count dict from [PreventiveFlag == 0] records\n",
    "df_w2c_id_np = GetItemDescW2Freq(df_p2_npflag)\n",
    "df_w2c_id_np['is_preventive'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>is_preventive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leptospirosis</td>\n",
       "      <td>0.690369</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vaccine</td>\n",
       "      <td>3.175699</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canine</td>\n",
       "      <td>2.312737</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>illness</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>case</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>pk</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word     count  is_preventive\n",
       "0     Leptospirosis  0.690369           True\n",
       "1           Vaccine  3.175699           True\n",
       "2            Canine  2.312737           True\n",
       "...             ...       ...            ...\n",
       "5777        illness  0.002829          False\n",
       "5778           case  0.002829          False\n",
       "5779             pk  0.002829          False\n",
       "\n",
       "[6647 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w2c_id_merged = pd.concat([df_w2c_id_p, df_w2c_id_np])\n",
    "df_w2c_id_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2c_id_merged.to_csv('./Data/WordFreqItemDesc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count_p</th>\n",
       "      <th>count_np</th>\n",
       "      <th>diff_p_np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leptospirosis</td>\n",
       "      <td>0.690369</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.687540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vaccine</td>\n",
       "      <td>3.175699</td>\n",
       "      <td>0.048096</td>\n",
       "      <td>3.127603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canine</td>\n",
       "      <td>2.312737</td>\n",
       "      <td>0.987382</td>\n",
       "      <td>1.325355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>Fi</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>-0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>illness</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>-0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>case</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>-0.002829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6176 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word   count_p  count_np  diff_p_np\n",
       "0     Leptospirosis  0.690369  0.002829   0.687540\n",
       "1           Vaccine  3.175699  0.048096   3.127603\n",
       "2            Canine  2.312737  0.987382   1.325355\n",
       "...             ...       ...       ...        ...\n",
       "6173             Fi  0.000000  0.002829  -0.002829\n",
       "6174        illness  0.000000  0.002829  -0.002829\n",
       "6175           case  0.000000  0.002829  -0.002829\n",
       "\n",
       "[6176 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w2c_id_merged_col = df_w2c_id_p.merge(df_w2c_id_np, how='outer', left_on='word', right_on='word')\n",
    "df_w2c_id_merged_col = df_w2c_id_merged_col[['word', 'count_x', 'count_y']]\n",
    "df_w2c_id_merged_col['count_x'].fillna(0, inplace=True)\n",
    "df_w2c_id_merged_col['count_y'].fillna(0, inplace=True)\n",
    "df_w2c_id_merged_col.columns = ['word', 'count_p', 'count_np']\n",
    "df_w2c_id_merged_col['diff_p_np'] = df_w2c_id_merged_col['count_p'] - df_w2c_id_merged_col['count_np']\n",
    "df_w2c_id_merged_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2c_id_merged_col.to_csv('./Data/WordFreqItemDescDiff.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're able to see what are the most freqently occurred words for both preventive and non-preventive scenarios\n",
    "\n",
    "![Word Frequency ItemDescription](Images/PetPic02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the frequency of words in ItemDescription for both preventive and non-preventive case, it can be seen some of the words are strong indicators for certain category.\n",
    "\n",
    "The numbers in both left and right images are percentage, you might see the numbers are very small, but consider the amount of words, even two words with difference of 0.5 would mean a big difference in occurence.\n",
    "\n",
    "#### Insights:\n",
    "\n",
    "* Words like Vaccine, Bordetella, Rabies, Canine, Fecal, Annual, Heartgard, Interceptor have much higher occurence frequency in prentive catogory\n",
    "* Words like Exam, mg, Consultation, Examination, Recheck, etc. have much higher occurence frequency in non-prentive category\n",
    "* For reasons unclear, some words, like 3, 1, 6 has unusual bound to a certain category.\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "Through the data exploration process, now we have a better understanding of our data, the next step is to figure out how to generate the model for our classification task, we could try traditional machine learning feature engineering way, then the exploration results can be used as a reference for that process, or we could also use deep learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a decision has to be made in which way to go, I'm lean more towards to the deep learning way, for text classification task, TextCNN seems a good way to go. Then the real next step is to prepare our data, splitting our current dataset into three parts: train set, validation set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 644\n",
      "466 8856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PreventiveFlag</th>\n",
       "      <th>CombinedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Shayna:  Leptospirosis Vaccine | Transitional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>RAPHAEL:  Canine Rabies Booster 3 year | Lyme ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>Reese:  Bordetella Oral - Annual | Exam &amp; Anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>Stella:  Doxycycline 100mg/ml | Heart Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>MILLIE:  Adequan Injection per cc | Complicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>MILLIE:  Biohazard Waste Disposal Fee | Compli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PreventiveFlag                                       CombinedText\n",
       "13                 1  Shayna:  Leptospirosis Vaccine | Transitional ...\n",
       "47                 1  RAPHAEL:  Canine Rabies Booster 3 year | Lyme ...\n",
       "52                 1  Reese:  Bordetella Oral - Annual | Exam & Anal...\n",
       "...              ...                                                ...\n",
       "9997               0     Stella:  Doxycycline 100mg/ml | Heart Disease \n",
       "9998               0  MILLIE:  Adequan Injection per cc | Complicati...\n",
       "9999               0  MILLIE:  Biohazard Waste Disposal Fee | Compli...\n",
       "\n",
       "[9500 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 7)\n",
    "\n",
    "ntest = 10000\n",
    "df_p2_all = pd.read_csv('./Data/p2_data.csv', encoding='latin1')\n",
    "df_p2_all_p = df_p2_all[df_p2_all['PreventiveFlag'] == 1]\n",
    "df_p2_all_np = df_p2_all[df_p2_all['PreventiveFlag'] == 0]\n",
    "\n",
    "df_p2_val_p = df_p2_all_p.sample(frac=0.05)\n",
    "df_p2_trn_p = df_p2_all_p.append(df_p2_val_p).drop_duplicates(keep=False)\n",
    "print(len(df_p2_val_p), len(df_p2_trn_p))\n",
    "\n",
    "df_p2_val_np = df_p2_all_np.sample(frac=0.05)\n",
    "df_p2_trn_np = df_p2_all_np.append(df_p2_val_np).drop_duplicates(keep=False)\n",
    "print(len(df_p2_val_np), len(df_p2_trn_np))\n",
    "\n",
    "df_p2_all_tst = df_p2_all[np.isnan(df_p2_all['PreventiveFlag'])]\n",
    "\n",
    "def ConstructDatasetCore(df):\n",
    "    df['CombinedText'] = df['ItemDescription'] + ' | ' + df['Diagnosis']\n",
    "    del df['ItemDescription']\n",
    "    del df['Diagnosis']\n",
    "    try:\n",
    "        df['PreventiveFlag'] = df['PreventiveFlag'].astype(int)\n",
    "        del df['id']\n",
    "    except:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "def ConstructTrnValDataset(df_p, df_np, path):\n",
    "    df = pd.concat([df_p, df_np])\n",
    "    df = ConstructDatasetCore(df)\n",
    "    df.to_csv(path, index=False)\n",
    "    return df\n",
    "\n",
    "def ConstructTstDataset(df_p, path):\n",
    "    df = df_p.copy()\n",
    "    df = ConstructDatasetCore(df)\n",
    "    df.to_csv(path, index=False)\n",
    "    return df\n",
    "\n",
    "ConstructTstDataset(df_p2_all_tst, './Data/p2_tst.csv')\n",
    "ConstructTrnValDataset(df_p2_val_p, df_p2_val_np, './Data/p2_val.csv')\n",
    "ConstructTrnValDataset(df_p2_trn_p, df_p2_trn_np, './Data/p2_trn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PreventiveFlag</th>\n",
       "      <th>CombinedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cocoa:  Sentinel Yellow (26 - 50 lbs) | Thyro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coco Chanel:  Heartgard Plus K9 S 1-25lb/1-11k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Teddy:  Sentinel Yellow 11.5/230 mg, 12-22kg |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>Seco:  Cortisol (2) ACTH Stimulation T440 ACTH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>Linus:  Urine Test Strip | Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>Angie:  Consultation per 10 min | Recheck of CHF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PreventiveFlag                                       CombinedText\n",
       "0                 1  Cocoa:  Sentinel Yellow (26 - 50 lbs) | Thyro-...\n",
       "1                 1  Coco Chanel:  Heartgard Plus K9 S 1-25lb/1-11k...\n",
       "2                 1  Teddy:  Sentinel Yellow 11.5/230 mg, 12-22kg |...\n",
       "..              ...                                                ...\n",
       "497               0  Seco:  Cortisol (2) ACTH Stimulation T440 ACTH...\n",
       "498               0               Linus:  Urine Test Strip | Diabetes \n",
       "499               0  Angie:  Consultation per 10 min | Recheck of CHF \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./Data/p2_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PreventiveFlag</th>\n",
       "      <th>CombinedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MILLIE:  Polygylcan SA IM Arthritis Inj per ML...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ebbet:  Zignature Kangaroo Formula 13oz. | vom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ginger:  Office Visit | ear infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>10998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Theo:  Thyroid Free T4 (ED) Add on - ADD50 | e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>10999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MYSTIQUE:  Exam/Medical Progress FollowUp | De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>11000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cricket:  RAD FollowUp Radiograph | Vomiting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  PreventiveFlag                                       CombinedText\n",
       "0    10001             NaN  MILLIE:  Polygylcan SA IM Arthritis Inj per ML...\n",
       "1    10002             NaN  Ebbet:  Zignature Kangaroo Formula 13oz. | vom...\n",
       "2    10003             NaN             Ginger:  Office Visit | ear infection \n",
       "..     ...             ...                                                ...\n",
       "997  10998             NaN  Theo:  Thyroid Free T4 (ED) Add on - ADD50 | e...\n",
       "998  10999             NaN  MYSTIQUE:  Exam/Medical Progress FollowUp | De...\n",
       "999  11000             NaN      Cricket:  RAD FollowUp Radiograph | Vomiting \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./Data/p2_tst.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/validation/test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "# Use spacy as the tokenizer\n",
    "tokenize = lambda x: [tok.text for tok in spacy_en.tokenizer(x)]\n",
    "\n",
    "# Convert to lowercase & Tokenize\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)\n",
    "\n",
    "# Labels are already processed\n",
    "LABEL = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "tv_datafields = [(\"PreventiveFlag\", LABEL), (\"CombinedText\", TEXT)]\n",
    "\n",
    "trn, vld = TabularDataset.splits(\n",
    "        path=\"./Data\",\n",
    "        train='p2_trn.csv', validation=\"p2_val.csv\",\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=tv_datafields)\n",
    "\n",
    "tst_datafields = [(\"PreventiveFlag\", None), (\"CombinedText\", TEXT)]\n",
    "\n",
    "tst = TabularDataset(\n",
    "        path=\"Data/p2_tst.csv\",\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=tst_datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moss', ':', ' ', 'interceptor', 'plus', '11.4', '-', '22.7', 'kg', '(', 'yellow', ')', '|', 'diarrhea']\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "print(trn[15].CombinedText)\n",
    "print(len(trn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn, vectors=\"glove.6B.100d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 11488),\n",
       " (':', 9779),\n",
       " ('|', 9507),\n",
       " ('-', 2614),\n",
       " ('/', 2599),\n",
       " (',', 1771),\n",
       " (')', 1660),\n",
       " ('(', 1655),\n",
       " ('mg', 1424),\n",
       " ('exam', 939)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.stoi[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "trn_iter, vld_iter = BucketIterator.splits(\n",
    "    (trn, vld), # we pass in the datasets we want the iterator to draw data from\n",
    "    batch_sizes=(64, 64),\n",
    "    device=torch.device('cuda:0'), # Use GPU\n",
    "    sort_key=lambda x: len(x.CombinedText),\n",
    "    sort_within_batch=False,\n",
    "    repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")\n",
    "\n",
    "tst_iter = Iterator(\n",
    "    tst, \n",
    "    batch_size=64, \n",
    "    device=torch.device('cuda:0'), \n",
    "    sort=False, \n",
    "    sort_within_batch=False, \n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.PreventiveFlag]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
      "\t[.CombinedText]:[torch.cuda.LongTensor of size 34x64 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(trn_iter))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nb.CombinedText[10]\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "b.CombinedText[10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nb.CombinedText[0].size()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "b.CombinedText[0].size()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping the iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, xvar, yvar):\n",
    "        # we pass in the list of attributes for x and y\n",
    "        self.dl, self.xvar, self.yvar = dl, xvar, yvar\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            # we assume only one input in this wrapper\n",
    "            x = getattr(batch, self.xvar)\n",
    "            \n",
    "            if self.yvar is not None:\n",
    "                y = torch.cat([getattr(batch, self.yvar).unsqueeze(1)], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "\n",
    "trn_dl = BatchWrapper(trn_iter, \"CombinedText\", \"PreventiveFlag\")\n",
    "vld_dl = BatchWrapper(vld_iter, \"CombinedText\", \"PreventiveFlag\")\n",
    "tst_dl = BatchWrapper(tst_iter, \"CombinedText\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnext(trn_dl.__iter__())\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "next(trn_dl.__iter__())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Text CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        self.args = args\n",
    "        \n",
    "        V = args.embed_num\n",
    "        D = args.embed_dim\n",
    "        C = args.class_num\n",
    "        Ci = 1\n",
    "        Co = args.kernel_num\n",
    "        Ks = args.kernel_sizes\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D)\n",
    "        # print(x.size())\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7071\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "args = Object()\n",
    "args.embed_num = len(TEXT.vocab)\n",
    "args.embed_dim = 128\n",
    "args.dropout = 0.5\n",
    "args.class_num = 2\n",
    "args.kernel_num = 100\n",
    "args.kernel_sizes = [3, 4, 5]\n",
    "args.save_dir = os.path.join('Chkpt', datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "\n",
    "print(args.embed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN_Text(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "args.lr = 1e-5\n",
    "args.epochs = 1000\n",
    "\n",
    "def save(model, save_dir, save_prefix, steps):\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_prefix = os.path.join(save_dir, save_prefix)\n",
    "    save_path = '{}_steps_{}.pt'.format(save_prefix, steps)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "def train(trn_iter, vld_iter, model, args):\n",
    "    model.cuda()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    best_acc = 0\n",
    "    last_step = 0\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    step = 0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        step += 1\n",
    "        crct_trn, acur_trn = 0, 0\n",
    "        crct_vld, acur_vld = 0, 0\n",
    "        \n",
    "        for batch in trn_iter:\n",
    "            feature, target = batch.CombinedText, batch.PreventiveFlag\n",
    "            optim.zero_grad()\n",
    "            feature.transpose_(0, 1)\n",
    "            logit = model(feature)\n",
    "            loss = F.cross_entropy(logit, target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += loss.data.item() * feature.size(0)\n",
    "            crct_trn += (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "        epoch_loss = running_loss / len(trn)\n",
    "        acur_trn = crct_trn.data.item() * 1.0 / len(trn)\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        model.eval() # turn on evaluation mode\n",
    "        for batch in vld_iter:\n",
    "            feature, target = batch.CombinedText, batch.PreventiveFlag\n",
    "            feature.transpose_(0, 1)\n",
    "            logit = model(feature)\n",
    "            loss = F.cross_entropy(logit, target)\n",
    "            val_loss += loss.data.item() * feature.size(0)\n",
    "            crct_vld += (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "        acur_vld = crct_vld.data.item() / len(vld)\n",
    "\n",
    "        val_loss /= len(vld)\n",
    "        if step % 15 == 1:\n",
    "            print('Epoch: {}, Trn Loss: {:.4f}, Val Loss: {:.4f}, acc_trn: {:.4f}({}/{}), acc_vld: {:.4f}({}/{})'\n",
    "                  .format(epoch, epoch_loss, val_loss, acur_trn, crct_trn.data.item(), len(trn), acur_vld, crct_vld.data.item(), len(vld)))\n",
    "            save(model, args.save_dir, 'snapshot', step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Trn Loss: 0.3024, Val Loss: 0.2625, acc_trn: 0.9228(8767/9500), acc_vld: 0.9320(466/500)\n",
      "Epoch: 16, Trn Loss: 3.4010, Val Loss: 0.1970, acc_trn: 0.9343(8876/9500), acc_vld: 0.9340(467/500)\n",
      "Epoch: 31, Trn Loss: 5.4319, Val Loss: 0.1478, acc_trn: 0.9588(9109/9500), acc_vld: 0.9520(476/500)\n",
      "Epoch: 46, Trn Loss: 6.7918, Val Loss: 0.1217, acc_trn: 0.9738(9251/9500), acc_vld: 0.9580(479/500)\n",
      "Epoch: 61, Trn Loss: 7.7428, Val Loss: 0.1065, acc_trn: 0.9840(9348/9500), acc_vld: 0.9660(483/500)\n",
      "Epoch: 76, Trn Loss: 8.4092, Val Loss: 0.0970, acc_trn: 0.9914(9418/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 91, Trn Loss: 8.8684, Val Loss: 0.0909, acc_trn: 0.9957(9459/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 106, Trn Loss: 9.1779, Val Loss: 0.0880, acc_trn: 0.9988(9489/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 121, Trn Loss: 9.3828, Val Loss: 0.0867, acc_trn: 0.9996(9496/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 136, Trn Loss: 9.5172, Val Loss: 0.0875, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 151, Trn Loss: 9.6051, Val Loss: 0.0893, acc_trn: 0.9999(9499/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 166, Trn Loss: 9.6633, Val Loss: 0.0918, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 181, Trn Loss: 9.7026, Val Loss: 0.0952, acc_trn: 0.9999(9499/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 196, Trn Loss: 9.7299, Val Loss: 0.0987, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 211, Trn Loss: 9.7499, Val Loss: 0.1015, acc_trn: 0.9999(9499/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 226, Trn Loss: 9.7651, Val Loss: 0.1043, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 241, Trn Loss: 9.7776, Val Loss: 0.1068, acc_trn: 0.9999(9499/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 256, Trn Loss: 9.7881, Val Loss: 0.1094, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 271, Trn Loss: 9.7970, Val Loss: 0.1108, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 286, Trn Loss: 9.8050, Val Loss: 0.1126, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 301, Trn Loss: 9.8123, Val Loss: 0.1148, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 316, Trn Loss: 9.8189, Val Loss: 0.1174, acc_trn: 0.9999(9499/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 331, Trn Loss: 9.8252, Val Loss: 0.1175, acc_trn: 0.9998(9498/9500), acc_vld: 0.9720(486/500)\n",
      "Epoch: 346, Trn Loss: 9.8309, Val Loss: 0.1204, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 361, Trn Loss: 9.8365, Val Loss: 0.1206, acc_trn: 0.9999(9499/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 376, Trn Loss: 9.8418, Val Loss: 0.1217, acc_trn: 0.9999(9499/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 391, Trn Loss: 9.8470, Val Loss: 0.1224, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 406, Trn Loss: 9.8520, Val Loss: 0.1235, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 421, Trn Loss: 9.8569, Val Loss: 0.1252, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 436, Trn Loss: 9.8617, Val Loss: 0.1255, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 451, Trn Loss: 9.8664, Val Loss: 0.1261, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 466, Trn Loss: 9.8710, Val Loss: 0.1283, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 481, Trn Loss: 9.8752, Val Loss: 0.1287, acc_trn: 0.9999(9499/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 496, Trn Loss: 9.8797, Val Loss: 0.1299, acc_trn: 0.9998(9498/9500), acc_vld: 0.9680(484/500)\n",
      "Epoch: 511, Trn Loss: 9.8840, Val Loss: 0.1295, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 526, Trn Loss: 9.8883, Val Loss: 0.1309, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 541, Trn Loss: 9.8924, Val Loss: 0.1308, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 556, Trn Loss: 9.8968, Val Loss: 0.1312, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 571, Trn Loss: 9.9008, Val Loss: 0.1318, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 586, Trn Loss: 9.9048, Val Loss: 0.1325, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 601, Trn Loss: 9.9088, Val Loss: 0.1337, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 616, Trn Loss: 9.9129, Val Loss: 0.1341, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 631, Trn Loss: 9.9168, Val Loss: 0.1349, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 646, Trn Loss: 9.9208, Val Loss: 0.1353, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 661, Trn Loss: 9.9245, Val Loss: 0.1349, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 676, Trn Loss: 9.9284, Val Loss: 0.1364, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 691, Trn Loss: 9.9323, Val Loss: 0.1363, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 706, Trn Loss: 9.9362, Val Loss: 0.1373, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 721, Trn Loss: 9.9401, Val Loss: 0.1379, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 736, Trn Loss: 9.9439, Val Loss: 0.1388, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 751, Trn Loss: 9.9477, Val Loss: 0.1388, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 766, Trn Loss: 9.9516, Val Loss: 0.1393, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 781, Trn Loss: 9.9552, Val Loss: 0.1385, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 796, Trn Loss: 9.9588, Val Loss: 0.1389, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 811, Trn Loss: 9.9625, Val Loss: 0.1407, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 826, Trn Loss: 9.9662, Val Loss: 0.1399, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 841, Trn Loss: 9.9699, Val Loss: 0.1401, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 856, Trn Loss: 9.9737, Val Loss: 0.1406, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 871, Trn Loss: 9.9775, Val Loss: 0.1411, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 886, Trn Loss: 9.9813, Val Loss: 0.1423, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 901, Trn Loss: 9.9849, Val Loss: 0.1424, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 916, Trn Loss: 9.9887, Val Loss: 0.1416, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 931, Trn Loss: 9.9924, Val Loss: 0.1418, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 946, Trn Loss: 9.9962, Val Loss: 0.1434, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 961, Trn Loss: 9.9997, Val Loss: 0.1430, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 976, Trn Loss: 10.0034, Val Loss: 0.1440, acc_trn: 0.9999(9499/9500), acc_vld: 0.9700(485/500)\n",
      "Epoch: 991, Trn Loss: 10.0071, Val Loss: 0.1431, acc_trn: 0.9998(9498/9500), acc_vld: 0.9700(485/500)\n"
     ]
    }
   ],
   "source": [
    "train(trn_iter, vld_iter, cnn, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems epoch 121 achieves the best validation accuracy, we use checkpoint from this epoch to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Text(\n",
       "  (embed): Embedding(7071, 128)\n",
       "  (convs1): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(3, 128), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(4, 128), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(5, 128), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (fc1): Linear(in_features=300, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_eval = CNN_Text(args)\n",
    "cnn_eval.load_state_dict(torch.load('./Chkpt/2019-02-25_00-00-37/snapshot_steps_121.pt'))\n",
    "cnn_eval = cnn_eval.cuda()\n",
    "cnn_eval.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1\n",
      "2 0 1\n",
      "3 0 1\n",
      "8 0 1\n",
      "11 0 1\n",
      "12 0 1\n",
      "14 0 1\n",
      "19 0 1\n",
      "26 0 1\n",
      "32 0 1\n",
      "33 0 1\n",
      "Sales Tax | Dermatitis \n",
      "137 1 0\n",
      "218 1 0\n",
      "238 1 0\n",
      "298 1 0\n",
      "373 1 0\n",
      "Sales Tax | Wellness \n"
     ]
    }
   ],
   "source": [
    "df_vld = pd.read_csv('./Data/p2_val.csv')\n",
    "\n",
    "for i in range(len(df_vld)):\n",
    "    PreventiveFlag = df_vld.iloc[i]['PreventiveFlag']\n",
    "    CombinedText = df_vld.iloc[i]['CombinedText']\n",
    "    text = TEXT.preprocess(CombinedText)\n",
    "    text = [[TEXT.vocab.stoi[x] for x in text]]\n",
    "    x = torch.tensor(text)\n",
    "    x = x.cuda()\n",
    "    try:\n",
    "        output = cnn_eval(x)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted = predicted.data.item()\n",
    "    \n",
    "        if predicted != PreventiveFlag:\n",
    "            print(i, predicted, PreventiveFlag)\n",
    "    except:\n",
    "        pass\n",
    "        print(CombinedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Tax | Vomiting \n"
     ]
    }
   ],
   "source": [
    "df_tst = pd.read_csv('./Data/p2_tst.csv')\n",
    "\n",
    "for i in range(len(df_tst)):\n",
    "    PreventiveFlag = df_tst.iloc[i]['PreventiveFlag']\n",
    "    CombinedText = df_tst.iloc[i]['CombinedText']\n",
    "    text = TEXT.preprocess(CombinedText)\n",
    "    text = [[TEXT.vocab.stoi[x] for x in text]]\n",
    "    x = torch.tensor(text)\n",
    "    x = x.cuda()\n",
    "    try:\n",
    "        output = cnn_eval(x)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted = predicted.data.item()\n",
    "        df_tst.iloc[i, df_tst.columns.get_loc('PreventiveFlag')] = int(predicted)\n",
    "    except:\n",
    "        pass\n",
    "        print(CombinedText)\n",
    "        df_tst.iloc[i, df_tst.columns.get_loc('PreventiveFlag')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst['PreventiveFlag'] = df_tst['PreventiveFlag'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PreventiveFlag</th>\n",
       "      <th>CombinedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "      <td>MILLIE:  Polygylcan SA IM Arthritis Inj per ML...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>Ebbet:  Zignature Kangaroo Formula 13oz. | vom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>0</td>\n",
       "      <td>Ginger:  Office Visit | ear infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>10998</td>\n",
       "      <td>0</td>\n",
       "      <td>Theo:  Thyroid Free T4 (ED) Add on - ADD50 | e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>10999</td>\n",
       "      <td>0</td>\n",
       "      <td>MYSTIQUE:  Exam/Medical Progress FollowUp | De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>11000</td>\n",
       "      <td>0</td>\n",
       "      <td>Cricket:  RAD FollowUp Radiograph | Vomiting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  PreventiveFlag                                       CombinedText\n",
       "0    10001               0  MILLIE:  Polygylcan SA IM Arthritis Inj per ML...\n",
       "1    10002               0  Ebbet:  Zignature Kangaroo Formula 13oz. | vom...\n",
       "2    10003               0             Ginger:  Office Visit | ear infection \n",
       "..     ...             ...                                                ...\n",
       "997  10998               0  Theo:  Thyroid Free T4 (ED) Add on - ADD50 | e...\n",
       "998  10999               0  MYSTIQUE:  Exam/Medical Progress FollowUp | De...\n",
       "999  11000               0      Cricket:  RAD FollowUp Radiograph | Vomiting \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst.to_csv('./Data/p2_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
